{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from datasketch import MinHash,MinHashLSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =pd.read_csv(\"tweets_2022_abril_junio.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subconjunto = df.copy()\n",
    "s = 0.4\n",
    "k = 4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spanish_stopwords = stopwords.words('spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ô∏è ayudenme favor conseguir informacion normas articulos cc rechazado. esto import‚Ä¶'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "frase = \"RT @RudyPetrikowski: ‚ö†Ô∏è Ay√∫denme por favor a conseguir la informaci√≥n de las normas o art√≠culos que la CC ha rechazado.\\n\\nEsto es muy import‚Ä¶\"\n",
    "def eliminar_stopwords(frase):\n",
    "    palabras = frase.split(\" \")\n",
    "    retorno = []\n",
    "    for palabra in palabras:\n",
    "        if not palabra in spanish_stopwords:\n",
    "            retorno.append(palabra)\n",
    "    return \" \".join(retorno)\n",
    "def procesar_frase(frase):\n",
    "    if (frase.startswith(\"RT\")):\n",
    "        frase = ' '.join(frase.split(\": \")[1:])\n",
    "    \n",
    "    # sin hashatgs\n",
    "    frase = re.sub(r\"#\\w+\", \"\",frase)\n",
    "    # sin url\n",
    "    frase = re.sub(r\"https\\S+\", \"\",frase)\n",
    "    # sin emojis\n",
    "    patron_emoji = re.compile(\"[\\U0001F600-\\U0001F64F]|[\\U0001F300-\\U0001F5FF]|[\\U0001F680-\\U0001F6FF]|[\\U00002600-\\U000027BF]|[\\U0001F900-\\U0001F9FF]|[\\U0001F1E0-\\U0001F1FF]|[\\U0001F1F2-\\U0001F1F4]|[\\U0001F1E6-\\U0001F1FF]\")\n",
    "    frase = re.sub(patron_emoji, '', frase)\n",
    "    # sin espacios\n",
    "    frase = re.sub(r\"\\s+\", \" \",frase)\n",
    "    # eliminar tildes\n",
    "    frase = frase.replace(\"√°\",\"a\")\n",
    "    frase = frase.replace(\"√©\",\"e\")\n",
    "    frase = frase.replace(\"√≠\",\"i\")\n",
    "    frase = frase.replace(\"√≥\",\"o\")\n",
    "    frase = frase.replace(\"√∫\",\"u\")\n",
    "\n",
    "    frase = eliminar_stopwords(frase)\n",
    "    \n",
    "    # minusculas\n",
    "    frase = frase.lower()\n",
    "    frase = frase.strip()\n",
    "    return frase\n",
    "\n",
    "procesar_frase(frase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1512186166438637582</td>\n",
       "      <td>h0l4d4ni3l4</td>\n",
       "      <td>RT @ValeMirandaCC: Tras casi 50 a√±os del golpe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1512186202367045642</td>\n",
       "      <td>Claudio70932894</td>\n",
       "      <td>RT @UTDTrabajoDigno: Ma√±ana jueves a las 18hrs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1512186287284924418</td>\n",
       "      <td>Cesar_A_RR</td>\n",
       "      <td>RT @JaimeGuajardoR: Aqu√≠ est√° el aporte de @te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1512186335754301446</td>\n",
       "      <td>rosmarieher</td>\n",
       "      <td>RT @melnicksergio: la pelotudez no tiene limit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1512186407841767424</td>\n",
       "      <td>GQuelluen</td>\n",
       "      <td>RT @BSepulvedaHales: Ante la circulaci√≥n de no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4549967</th>\n",
       "      <td>1526652300709679104</td>\n",
       "      <td>Alebarrera74</td>\n",
       "      <td>RT @DanielAbelLope1: @tere_marinovic üò°ü§Æüò°ü§Æ VIEJ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4549968</th>\n",
       "      <td>1526641118460334080</td>\n",
       "      <td>gigita29bq</td>\n",
       "      <td>RT @DanielAbelLope1: @tere_marinovic üò°ü§Æüò°ü§Æ VIEJ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4549969</th>\n",
       "      <td>1526738292011462657</td>\n",
       "      <td>Elizabe81480339</td>\n",
       "      <td>RT @Gonz1Gorjeperez: @tere_marinovic https://t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4549970</th>\n",
       "      <td>1526855280151056386</td>\n",
       "      <td>CastilloNafla</td>\n",
       "      <td>RT @Gonz1Gorjeperez: @tere_marinovic https://t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4549971</th>\n",
       "      <td>1526764015795310594</td>\n",
       "      <td>AndreaSakurada</td>\n",
       "      <td>RT @Gonz1Gorjeperez: @tere_marinovic https://t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4549972 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          id      screen_name   \n",
       "0        1512186166438637582      h0l4d4ni3l4  \\\n",
       "1        1512186202367045642  Claudio70932894   \n",
       "2        1512186287284924418       Cesar_A_RR   \n",
       "3        1512186335754301446      rosmarieher   \n",
       "4        1512186407841767424        GQuelluen   \n",
       "...                      ...              ...   \n",
       "4549967  1526652300709679104     Alebarrera74   \n",
       "4549968  1526641118460334080       gigita29bq   \n",
       "4549969  1526738292011462657  Elizabe81480339   \n",
       "4549970  1526855280151056386    CastilloNafla   \n",
       "4549971  1526764015795310594   AndreaSakurada   \n",
       "\n",
       "                                                      text  \n",
       "0        RT @ValeMirandaCC: Tras casi 50 a√±os del golpe...  \n",
       "1        RT @UTDTrabajoDigno: Ma√±ana jueves a las 18hrs...  \n",
       "2        RT @JaimeGuajardoR: Aqu√≠ est√° el aporte de @te...  \n",
       "3        RT @melnicksergio: la pelotudez no tiene limit...  \n",
       "4        RT @BSepulvedaHales: Ante la circulaci√≥n de no...  \n",
       "...                                                    ...  \n",
       "4549967  RT @DanielAbelLope1: @tere_marinovic üò°ü§Æüò°ü§Æ VIEJ...  \n",
       "4549968  RT @DanielAbelLope1: @tere_marinovic üò°ü§Æüò°ü§Æ VIEJ...  \n",
       "4549969  RT @Gonz1Gorjeperez: @tere_marinovic https://t...  \n",
       "4549970  RT @Gonz1Gorjeperez: @tere_marinovic https://t...  \n",
       "4549971  RT @Gonz1Gorjeperez: @tere_marinovic https://t...  \n",
       "\n",
       "[4549972 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "subconjunto = subconjunto.drop_duplicates([\"screen_name\",\"text\"]).reset_index(drop=True)\n",
    "subconjunto = subconjunto[[\"id\",\"screen_name\",\"text\"]]\n",
    "subconjunto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subconjunto[\"text\"] = subconjunto[\"text\"].apply(procesar_frase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shingle(frase , tama√±o_ventana):\n",
    "    lista = []\n",
    "    for i in range(len(frase) - tama√±o_ventana +1):\n",
    "        shingle = ' '.join(frase[i:i+tama√±o_ventana])\n",
    "        lista.append(shingle)\n",
    "    return ','.join(lista)\n",
    "subconjunto[\"text\"] = subconjunto[\"text\"].str.split().apply(lambda x: np.array(x)).apply(lambda x: shingle(x,k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subconjunto = subconjunto[subconjunto['text'].apply(lambda x: len(x.split()) > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subconjunto = subconjunto.reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweeets-Usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agrupado = subconjunto.copy()\n",
    "agrupado = agrupado.reset_index()\n",
    "agrupado = agrupado.groupby('screen_name')['index'].agg(list)\n",
    "agrupado = agrupado.rename('indices_en_lista')\n",
    "agrupado = agrupado.reset_index().rename(columns={'index': 'indices_en_lista'})\n",
    "agrupado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_caracteristica(subconjun):\n",
    "    tweets = subconjun\n",
    "    shingles = tweets['text'].apply(lambda x: np.array(x.split(',')))\n",
    "    mlb = MultiLabelBinarizer(sparse_output=True)\n",
    "    return mlb.fit_transform(shingles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4019415x5806559 sparse matrix of type '<class 'numpy.int32'>'\n",
       "\twith 35557046 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "matrix = m_caracteristica(subconjunto)\n",
    "matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pm= 10\n",
    "\n",
    "def minhash_vec(sparce_vector):\n",
    "    minhash = MinHash(n_pm)\n",
    "    for i in sparce_vector.indices:\n",
    "        minhash.update(str(i).encode(\"utf8\"))\n",
    "    return minhash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thrld = 0.4\n",
    "lsh = MinHashLSH(thrld,n_pm)\n",
    "list_hash = []\n",
    "for i in range(matrix.shape[0]):\n",
    "    list_hash.append((i,minhash_vec(matrix[i])))\n",
    "\n",
    "with lsh.insertion_session() as session:\n",
    "    for i , minhash in list_hash:\n",
    "        session.insert(i, minhash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4019415"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(list_hash)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asociamos los tweets a sus buckets similares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformar_lista(lisa_id_tweet):\n",
    "    similares = set()\n",
    "    for id_tweet in lisa_id_tweet:\n",
    "        m = minhash_vec(matrix[id_tweet])\n",
    "        aprox = lsh.query(m)\n",
    "        similares.update(aprox)\n",
    "    return list(similares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agrupado['similaritys'] = agrupado['indices_en_lista'].apply(transformar_lista)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asociammos los buckets de tweets, a los usuarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_caracteristica(subconjun):\n",
    "    sims = subconjun\n",
    "    shingles = sims['similaritys'].apply(lambda x: np.array(x.split(',')))\n",
    "    mlb = MultiLabelBinarizer(sparse_output=True)\n",
    "    return mlb.fit_transform(shingles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = m_caracteristica(agrupado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pm= 50\n",
    "thrld = 0.4\n",
    "lsh = MinHashLSH(thrld,n_pm)\n",
    "list_hash = []\n",
    "for i in range(matrix.shape[0]):\n",
    "    list_hash.append((i,minhash_vec(matrix[i])))\n",
    "\n",
    "with lsh.insertion_session() as session:\n",
    "    for i , minhash in list_hash:\n",
    "        session.insert(i, minhash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_usuario = 0\n",
    "m = minhash_vec(matrix[id_usuario])\n",
    "usuarios_similares = lsh.query(m)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
